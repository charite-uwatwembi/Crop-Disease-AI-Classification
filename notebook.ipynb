{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10828 images belonging to 11 classes.\n",
      "Found 2702 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# Define the path to your dataset folder\n",
    "dataset_path = 'Data/'\n",
    "\n",
    "# Set parameters for image processing\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Create ImageDataGenerator instance for training and validation\n",
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)  # Scale pixel values to [0, 1]\n",
    "\n",
    "# Load training data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',   # For multi-class classification\n",
    "    subset='training'           # Specify that this is for training data\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',   # For multi-class classification\n",
    "    subset='validation'         # Specify that this is for validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Simple CNN\n",
    "Here's a simple CNN model without optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.4507 - loss: 2.3341 - val_accuracy: 0.7620 - val_loss: 0.7123\n",
      "Epoch 2/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 1s/step - accuracy: 0.8369 - loss: 0.4899 - val_accuracy: 0.8316 - val_loss: 0.5171\n",
      "Epoch 3/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - accuracy: 0.9338 - loss: 0.2167 - val_accuracy: 0.8272 - val_loss: 0.5639\n",
      "Epoch 4/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 1s/step - accuracy: 0.9698 - loss: 0.1016 - val_accuracy: 0.8242 - val_loss: 0.6118\n",
      "Epoch 5/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 1s/step - accuracy: 0.9916 - loss: 0.0379 - val_accuracy: 0.8453 - val_loss: 0.6059\n",
      "Epoch 6/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0320 - val_accuracy: 0.8327 - val_loss: 0.6471\n",
      "Epoch 7/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.9833 - loss: 0.0524 - val_accuracy: 0.8368 - val_loss: 0.6997\n",
      "Epoch 8/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 1s/step - accuracy: 0.9842 - loss: 0.0446 - val_accuracy: 0.8320 - val_loss: 0.7334\n",
      "Epoch 9/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.0265 - val_accuracy: 0.8416 - val_loss: 0.7210\n",
      "Epoch 10/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 1s/step - accuracy: 0.9937 - loss: 0.0224 - val_accuracy: 0.8131 - val_loss: 0.8935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Define Model 1: A simple CNN\n",
    "def create_simple_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(train_data.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "simple_cnn = create_simple_cnn()\n",
    "\n",
    "# Train the model\n",
    "simple_cnn.fit(train_data, validation_data=val_data, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "simple_cnn.save('saved_models/model1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Optimized CNN\n",
    "Here's the optimized CNN model with techniques like dropout, batch normalization, and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 2s/step - accuracy: 0.2126 - loss: 5.1546 - val_accuracy: 0.2043 - val_loss: 4.6818\n",
      "Epoch 2/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 2s/step - accuracy: 0.1861 - loss: 2.3208 - val_accuracy: 0.1340 - val_loss: 5.0225\n",
      "Epoch 3/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 3s/step - accuracy: 0.1915 - loss: 2.3651 - val_accuracy: 0.1758 - val_loss: 6.6951\n",
      "Epoch 4/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m819s\u001b[0m 2s/step - accuracy: 0.1914 - loss: 2.3279 - val_accuracy: 0.2221 - val_loss: 2.2427\n",
      "Epoch 5/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1193s\u001b[0m 3s/step - accuracy: 0.1996 - loss: 2.2648 - val_accuracy: 0.1917 - val_loss: 2.3462\n",
      "Epoch 6/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 3s/step - accuracy: 0.1912 - loss: 2.2537 - val_accuracy: 0.1884 - val_loss: 3.1669\n",
      "Epoch 7/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 3s/step - accuracy: 0.2015 - loss: 2.2959 - val_accuracy: 0.1403 - val_loss: 183.5941\n",
      "Epoch 8/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 2s/step - accuracy: 0.1981 - loss: 2.2434 - val_accuracy: 0.2135 - val_loss: 2.2138\n",
      "Epoch 9/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 2s/step - accuracy: 0.1831 - loss: 2.2434 - val_accuracy: 0.2135 - val_loss: 2.2165\n",
      "Epoch 10/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 2s/step - accuracy: 0.1935 - loss: 2.2587 - val_accuracy: 0.2232 - val_loss: 2.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Define Model 2: Optimized CNN with dropout and batch normalization\n",
    "def create_optimized_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),  # Dropout layer for regularization\n",
    "        Dense(train_data.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "optimized_cnn = create_optimized_cnn()\n",
    "\n",
    "# Train the optimized model\n",
    "optimized_cnn.fit(train_data, validation_data=val_data, epochs=10)\n",
    "\n",
    "# Save the optimized model\n",
    "optimized_cnn.save('saved_models/model2.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13530 images belonging to 11 classes.\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 187ms/step - accuracy: 0.9516 - loss: 0.2141\n",
      "\u001b[1m423/423\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 299ms/step - accuracy: 0.1645 - loss: 2.3044\n",
      "Simple CNN Test Accuracy: 95.80%\n",
      "Optimized CNN Test Accuracy: 22.07%\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_data = datagen.flow_from_directory(\n",
    "    'Data',  # Adjust the path as necessary\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Ensure the order is maintained for predictions\n",
    ")\n",
    "\n",
    "# Evaluate both models on the test data\n",
    "simple_eval = simple_cnn.evaluate(test_data)\n",
    "optimized_eval = optimized_cnn.evaluate(test_data)\n",
    "\n",
    "print(f\"Simple CNN Test Accuracy: {simple_eval[1] * 100:.2f}%\")\n",
    "print(f\"Optimized CNN Test Accuracy: {optimized_eval[1] * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
