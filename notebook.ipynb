{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10828 images belonging to 11 classes.\n",
      "Found 2702 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# Define the path to your dataset folder\n",
    "dataset_path = 'Data/'\n",
    "\n",
    "# Set parameters for image processing\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Create ImageDataGenerator instance for training and validation\n",
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)  # Scale pixel values to [0, 1]\n",
    "\n",
    "# Load training data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',   # For multi-class classification\n",
    "    subset='training'           # Specify that this is for training data\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',   # For multi-class classification\n",
    "    subset='validation'         # Specify that this is for validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Simple CNN\n",
    "Here's a simple CNN model without optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 1s/step - accuracy: 0.4507 - loss: 2.3341 - val_accuracy: 0.7620 - val_loss: 0.7123\n",
      "Epoch 2/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 1s/step - accuracy: 0.8369 - loss: 0.4899 - val_accuracy: 0.8316 - val_loss: 0.5171\n",
      "Epoch 3/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 1s/step - accuracy: 0.9338 - loss: 0.2167 - val_accuracy: 0.8272 - val_loss: 0.5639\n",
      "Epoch 4/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 1s/step - accuracy: 0.9698 - loss: 0.1016 - val_accuracy: 0.8242 - val_loss: 0.6118\n",
      "Epoch 5/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 1s/step - accuracy: 0.9916 - loss: 0.0379 - val_accuracy: 0.8453 - val_loss: 0.6059\n",
      "Epoch 6/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0320 - val_accuracy: 0.8327 - val_loss: 0.6471\n",
      "Epoch 7/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.9833 - loss: 0.0524 - val_accuracy: 0.8368 - val_loss: 0.6997\n",
      "Epoch 8/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 1s/step - accuracy: 0.9842 - loss: 0.0446 - val_accuracy: 0.8320 - val_loss: 0.7334\n",
      "Epoch 9/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 1s/step - accuracy: 0.9908 - loss: 0.0265 - val_accuracy: 0.8416 - val_loss: 0.7210\n",
      "Epoch 10/10\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 1s/step - accuracy: 0.9937 - loss: 0.0224 - val_accuracy: 0.8131 - val_loss: 0.8935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Define Model 1: A simple CNN\n",
    "def create_simple_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(train_data.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "simple_cnn = create_simple_cnn()\n",
    "\n",
    "# Train the model\n",
    "simple_cnn.fit(train_data, validation_data=val_data, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "simple_cnn.save('saved_models/model1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Optimized CNN\n",
    "Here's the optimized CNN model with techniques like dropout, batch normalization, and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 22\u001b[0m optimized_cnn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_optimized_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the optimized model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimized_cnn\u001b[38;5;241m.\u001b[39mfit(train_data, validation_data\u001b[38;5;241m=\u001b[39mval_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m, in \u001b[0;36mcreate_optimized_cnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_optimized_cnn\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      4\u001b[0m         Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(img_height, img_width, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      5\u001b[0m         BatchNormalization(),\n\u001b[0;32m      6\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      7\u001b[0m         Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m         BatchNormalization(),\n\u001b[0;32m      9\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     10\u001b[0m         Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     11\u001b[0m         BatchNormalization(),\n\u001b[0;32m     12\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     13\u001b[0m         Flatten(),\n\u001b[0;32m     14\u001b[0m         Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     15\u001b[0m         Dropout(\u001b[38;5;241m0.5\u001b[39m),  \u001b[38;5;66;03m# Dropout layer for regularization\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         Dense(train_data\u001b[38;5;241m.\u001b[39mnum_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Output layer for multi-class classification\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     ])\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Define Model 2: Optimized CNN with dropout and batch normalization\n",
    "def create_optimized_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),  # Dropout layer for regularization\n",
    "        Dense(train_data.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "optimized_cnn = create_optimized_cnn()\n",
    "\n",
    "# Train the optimized model\n",
    "optimized_cnn.fit(train_data, validation_data=val_data, epochs=10)\n",
    "\n",
    "# Save the optimized model\n",
    "optimized_cnn.save('saved_models/model2.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = datagen.flow_from_directory(\n",
    "    'Data/test/',  # Adjust the path as necessary\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Ensure the order is maintained for predictions\n",
    ")\n",
    "\n",
    "# Evaluate both models on the test data\n",
    "simple_eval = simple_cnn.evaluate(test_data)\n",
    "optimized_eval = optimized_cnn.evaluate(test_data)\n",
    "\n",
    "print(f\"Simple CNN Test Accuracy: {simple_eval[1] * 100:.2f}%\")\n",
    "print(f\"Optimized CNN Test Accuracy: {optimized_eval[1] * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
